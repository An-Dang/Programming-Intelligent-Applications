{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Ideas\n",
    "\n",
    "### Change the Loss Function to Wasserstein Distance\n",
    "[Wasserstein GANs (WGAN)](https://arxiv.org/pdf/1701.07875.pdf) are an alternative to *classical* GANs. They use a different loss function and prooved to be more stable to hyperparameter selection. While the paper offers a good theoretical introduction and reasoning why they perform better in many cases, [this article](https://wiseodd.github.io/techblog/2017/02/04/wasserstein-gan/) provides a good practical introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "(train_X, train_y),(test_X, test_y) = load_data()\n",
    "\n",
    "train_X = train_X/255.0\n",
    "train_y = train_y/255.0\n",
    "\n",
    "test_X = test_X/255.0\n",
    "test_y = test_y/255.0\n",
    "\n",
    "\n",
    "train = np.append(train_X, test_X, axis=0) #Use both Train and Testset for GAN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"Vanilla GAN\"\"\"\n",
    "def discriminator(X, reuse_vars=None):\n",
    "    with tf.variable_scope('dis', reuse=reuse_vars):\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(inputs=X, filters=32, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "        pool1 = tf.layers.average_pooling2d(inputs=conv1, pool_size=[2,2], strides=2, name=\"pool1\")\n",
    "\n",
    "        conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "        pool2 = tf.layers.average_pooling2d(inputs=conv2, pool_size=[2,2], strides=2, name=\"pool2\")\n",
    "\n",
    "        flat_layer = tf.reshape(pool2, [-1, 7 * 7 * 64], name=\"flatten\")\n",
    "\n",
    "        # Dense layer\n",
    "        dense = tf.layers.dense(inputs=flat_layer, units=1024, activation=tf.nn.relu, name=\"dense\")\n",
    "\n",
    "        # Logits layer\n",
    "        logits = tf.layers.dense(inputs=dense, units=1, name=\"dense2\")\n",
    "        \n",
    "        #output = tf.sigmoid(logits, name=\"sigmoid\")\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WGAN\"\"\"\n",
    "def discriminator(X, reuse_vars=None):\n",
    "    with tf.variable_scope('dis', reuse=reuse_vars):\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(inputs=X, filters=32, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "        pool1 = tf.layers.average_pooling2d(inputs=conv1, pool_size=[2,2], strides=2, name=\"pool1\")\n",
    "\n",
    "        conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "        pool2 = tf.layers.average_pooling2d(inputs=conv2, pool_size=[2,2], strides=2, name=\"pool2\")\n",
    "\n",
    "        flat_layer = tf.reshape(pool2, [-1, 7 * 7 * 64], name=\"flatten\")\n",
    "\n",
    "        # Dense layer\n",
    "        dense = tf.layers.dense(inputs=flat_layer, units=1024, activation=tf.nn.relu, name=\"dense\")\n",
    "\n",
    "        # Logits layer\n",
    "        logits = tf.layers.dense(inputs=dense, units=1, name=\"dense2\")\n",
    "        \n",
    "        #output = tf.sigmoid(logits, name=\"sigmoid\")\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(noise, reuse_vars=None):\n",
    "    with tf.variable_scope(\"gen\", reuse=reuse_vars):\n",
    "        \n",
    "        # First DenseLayer\n",
    "        dense = tf.layers.dense(inputs=noise, units=3136, activation=tf.nn.relu, name=\"dense\")\n",
    "        \n",
    "        #Reshape\n",
    "        reshape = tf.reshape(dense, [-1, 56, 56, 1], name=\"reshape\")\n",
    "        \n",
    "        #1 Conv2d\n",
    "        conv1 = tf.layers.conv2d(inputs=reshape, filters=50, kernel_size=[3,3], strides=2, padding=\"same\", activation=tf.nn.relu, name=\"conv1\")\n",
    "        \n",
    "        #BatchNormalization\n",
    "        conv1_norm = tf.layers.batch_normalization(conv1, name=\"batch_norm1\")\n",
    "        \n",
    "        #Upsample\n",
    "        conv1_upsample = tf.image.resize_images(conv1_norm, (56,56))\n",
    "        \n",
    "        #2 Conv2d\n",
    "        conv2 = tf.layers.conv2d(inputs=conv1_upsample, filters=25, kernel_size=[3,3], strides=2, padding=\"same\", activation=tf.nn.relu, name=\"conv2\")\n",
    "        \n",
    "        #BatchNormalization\n",
    "        conv2_norm = tf.layers.batch_normalization(conv2, name=\"batch_norm2\")\n",
    "        \n",
    "        #Upsample\n",
    "        conv2_upsample = tf.image.resize_images(conv2_norm, (56,56))\n",
    "        \n",
    "        #2 Conv2d\n",
    "        logits = tf.layers.conv2d(inputs=conv2_upsample, filters=1, kernel_size=[3,3], strides=2, padding=\"same\", name=\"conv3\")\n",
    "        output = tf.nn.sigmoid(logits, name=\"sigmoid\")\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    real_images = tf.placeholder(tf.float32, shape=[None, 28,28,1], name=\"ImagePlaceholder\")\n",
    "    z = tf.placeholder(tf.float32, shape=[None, 100], name = \"NoisePlaceholder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"Vanilla GAN\"\"\"\n",
    "Gz = gen(z)\n",
    "D_output_real, D_logits_real = discriminator(real_images)\n",
    "D_output_fake, D_logits_fake = discriminator(Gz, reuse_vars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WGAN\"\"\"\n",
    "Gz = gen(z)\n",
    "D_logits_real = discriminator(real_images)\n",
    "D_logits_fake = discriminator(Gz, reuse_vars=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# LOSSES\n",
    "def loss_func (logits_in, labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits=logits_in, labels=labels_in, name=\"CrossEntropy\"), name=\"ReduceMean\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "D_real_loss = loss_func(D_logits_real, tf.ones_like(D_logits_real, name=\"Generator_Label\")*0.9)\n",
    "D_fake_loss = loss_func(D_logits_fake, tf.zeros_like(D_logits_fake, name=\"Discriminator_Label\"))\n",
    "\n",
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G_loss = loss_func(D_logits_fake, tf.ones_like(D_logits_fake, name=\"Generator_TrickLabel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WGAN\"\"\"\n",
    "D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "G_loss = -tf.reduce_mean(D_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WGAN\"\"\"\n",
    "# theta_D is list of D's params\n",
    "clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_learning_rate = 0.00005\n",
    "G_learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"Vanilla GAN\"\"\"\n",
    "d_vars = tf.trainable_variables(scope='dis')\n",
    "g_vars = tf.trainable_variables(scope='gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WGAN\"\"\"\n",
    "theta_D = tf.trainable_variables(scope='dis')\n",
    "theta_G = tf.trainable_variables(scope='gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_trainer = tf.train.RMSPropOptimizer(D_learning_rate, name=\"RMSPropOptimizer_Discriminator\").minimize(D_loss, var_list=d_vars, name=\"minimize_D_loss\")\n",
    "G_trainer = tf.train.RMSPropOptimizer(G_learning_rate, name=\"RMSPropOptimizer_Generator\").minimize(G_loss, var_list=g_vars, name=\"minimize_G_loss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train D more\"\"\"\n",
    "for it in range(1000000):\n",
    "    for _ in range(5):\n",
    "        X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "        _, D_loss_curr, _ = sess.run(\n",
    "            [D_solver, D_loss, clip_D],\n",
    "            feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}\n",
    "        )\n",
    "\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss],\n",
    "        feed_dict={z: sample_z(mb_size, z_dim)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Generated_Images:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"Dx_Loss\", D_real_loss)\n",
    "tf.summary.scalar(\"Dg_Loss\", D_fake_loss)\n",
    "tf.summary.scalar(\"D_loss\", D_loss)\n",
    "tf.summary.scalar(\"G_loss\", G_loss)\n",
    "tf.summary.image(\"Generated_Images\", Gz, max_outputs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 140000\n",
    "EPOCHS = 500000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "real = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Adding config for GPU - not using all of the GPUs Memory -> leading to crashes\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train = train.reshape(train.shape[0], 28, 28, 1).astype('float32')\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train).repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "iterator = train_dataset.make_one_shot_iterator()\n",
    "nextbatch = iterator.get_next()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2e4bed16a8ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpretrain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mbatch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#batch = mnist.train.next_batch(BATCH_SIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#with tf.Session(config=config) as sess:\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('./tensorboard/{0}_TrainableVariables_500K-Epochs'.format(now.strftime(\"%Y_%m_%d-%H-%M\")), sess.graph)\n",
    "    \n",
    "    for pretrain in tqdm(range(20)):\n",
    "        batch_images = sess.run(nextbatch)\n",
    "\n",
    "        #batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "        #batch_images = batch[0].reshape((BATCH_SIZE, 28,28))\n",
    "        #batch_images = np.expand_dims(batch_images, axis=-1)\n",
    "\n",
    "        #print(batch_images.shape)\n",
    "\n",
    "\n",
    "        #batch_images = batch_images * 2 - 1  # Use for TANH to remap between -1 and 1\n",
    "\n",
    "        batch_z = np.random.normal(0,1,size=(BATCH_SIZE,100))\n",
    "        _ = sess.run(D_trainer, feed_dict={real_images:batch_images, z:batch_z})\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        \n",
    "        #num_batches = len(train) // BATCH_SIZE\n",
    "        \n",
    "        #for batch in range(num_batches):\n",
    "            \n",
    "        batch_images = sess.run(nextbatch)\n",
    "\n",
    "        #batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "        #batch_images = batch[0].reshape((BATCH_SIZE, 28,28))\n",
    "        #batch_images = np.expand_dims(batch_images, axis=-1)\n",
    "\n",
    "        #print(batch_images.shape)\n",
    "\n",
    "\n",
    "        #batch_images = batch_images * 2 - 1  # Use for TANH to remap between -1 and 1\n",
    "\n",
    "\n",
    "        batch_z = np.random.normal(0,1,size=(BATCH_SIZE,100))\n",
    "        D_summary, _, discrloss, discr_r_loss, discr_f_loss = sess.run([merged, D_trainer, D_loss, D_real_loss, D_fake_loss], feed_dict={real_images:batch_images, z:batch_z})\n",
    "        genloss, _ = sess.run([G_loss, G_trainer], feed_dict={z:batch_z})\n",
    "\n",
    "        if (epoch % 10 == 0):{\n",
    "            # SUMMARIES\n",
    "            writer.add_summary(D_summary, epoch)\n",
    "            #print(genloss)\n",
    "        }\n",
    "\n",
    "        #print (\"ON EPOCH {}\".format(epoch))\n",
    "        \n",
    "        if (epoch%5000 == 0):\n",
    "            \n",
    "            sample_z = np.random.normal(0,1,size=(1,100))\n",
    "            gen_sample = sess.run(gen(z, reuse_vars=True), feed_dict={z: sample_z})\n",
    "            samples.append(gen_sample)\n",
    "            plt.imshow(gen_sample.reshape(28,28), cmap=\"gray\")\n",
    "            plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x127da85c0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.random.normal(0,1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
