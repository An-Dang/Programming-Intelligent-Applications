{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorflowTutorialMNIST_CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the network arcitecture to a convolutional NN\n",
    "\n",
    "Convolutional neural networks are used in state-of-the art image classifiaction networks. They learn a set of 2-d filters that are applied to the input image to generate meaningful features. \n",
    "\n",
    "For a theoretical introduction to how CNNs work, see the [Notebook on CNNs](http://nbviewer.jupyter.org/urls/maucher.home.hdm-stuttgart.de/nb/ML/ConvolutionNeuralNetworks.ipynb) from the Machine Learning lecture.\n",
    "\n",
    "1. reshape the input data to 2-dimensional 28x28 images\n",
    "2. replace the input layer with a [conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)\n",
    "3. add a [dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) layer followed by another conv2d layer and a final dropout layer before feeding the resulting feature maps into to the fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Teammember |                    |\n",
    "|------------|--------------------|\n",
    "| 1.         | Christopher Caldwell |\n",
    "| 2.         | Fabian MÃ¼ller      |\n",
    "| 3.         | An Dang         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    tf.set_random_seed(1234)\n",
    "    img_input = tf.reshape(features[\"X\"], [-1,28,28,1])\n",
    "    labels = tf.dtypes.cast(labels, tf.int64)\n",
    "    # Input layer - here as a conv2d layer #1\n",
    "    conv1 = tf.layers.conv2d(inputs=img_input, filters=32, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu)\n",
    "    \n",
    "    # Dropout layer #1\n",
    "    dropout1 = tf.layers.dropout(inputs=conv1, rate=0.3, training=mode == tf.estimator.ModeKeys.TRAIN, seed=(1234))\n",
    "    \n",
    "    # Conv2d layer #2\n",
    "    conv2 = tf.layers.conv2d(inputs=dropout1, filters=32, kernel_size=[5,5], padding=\"same\", activation=tf.nn.relu)\n",
    "      \n",
    "    # Dropout layer #2\n",
    "    dropout2 = tf.layers.dropout(inputs=conv2, rate=0.1, training=mode == tf.estimator.ModeKeys.TRAIN, seed=(1234))\n",
    "\n",
    "    flat_layer = tf.reshape(dropout2, [-1, 28 * 28 * 32])\n",
    "    \n",
    "    # Dense layer\n",
    "    dense = tf.layers.dense(inputs=flat_layer, units=1024, activation=tf.nn.relu)\n",
    "    \n",
    "    # Logits layer\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "       \n",
    "    # Compile the predictions in a dict and return EstimatorSpec as object\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis=1), \n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Calculate loss\n",
    "    print(labels)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # Training sgd\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Add evaluation - accuracy metrics\n",
    "    eval_metrice = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "(train_X, train_y),(test_X, test_y) = load_data()\n",
    "\n",
    "train_X = train_X/np.float(255)\n",
    "test_X = test_X/np.float(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator\n",
    "clf = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"minist_convent_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions - softmax_tensor from above\n",
    "tensor_to_log = {'probabilities': 'softmax_tensor'}\n",
    "\n",
    "# Log after every 50 steps \n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensor_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-2-17e6c49a41de>:6: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-17e6c49a41de>:9: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-2-17e6c49a41de>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "Tensor(\"Cast:0\", shape=(100,), dtype=int64)\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from minist_convent_model\\model.ckpt-10\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Fabi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 10 into minist_convent_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.09449036 0.09084276 0.09816158 0.09761644 0.09996095 0.09774982\n",
      "  0.10592655 0.10375839 0.11447336 0.09701979]\n",
      " [0.09825262 0.10395471 0.10246487 0.09824865 0.10051126 0.1007707\n",
      "  0.09701796 0.10097613 0.10119544 0.09660766]\n",
      " [0.09395704 0.1020295  0.10389446 0.10498639 0.10171193 0.09535752\n",
      "  0.09552787 0.09991535 0.10694916 0.09567078]\n",
      " [0.09871634 0.09465805 0.09627962 0.11851702 0.10372789 0.09753673\n",
      "  0.09660941 0.09563322 0.0965875  0.10173422]\n",
      " [0.09668531 0.0888668  0.10505362 0.10679882 0.09843557 0.09483735\n",
      "  0.0998346  0.09716379 0.11642785 0.09589628]\n",
      " [0.10215907 0.09366073 0.09526186 0.10770604 0.09988758 0.09472141\n",
      "  0.10298206 0.09878752 0.10551554 0.09931818]\n",
      " [0.09826989 0.09419208 0.09937019 0.11219301 0.10145852 0.09916379\n",
      "  0.09242784 0.08974129 0.11618002 0.0970034 ]\n",
      " [0.10066702 0.09073726 0.09946214 0.1016375  0.10550368 0.09697326\n",
      "  0.09596045 0.10633507 0.10750479 0.09521882]\n",
      " [0.10187667 0.09625991 0.09898727 0.10683409 0.10471329 0.09210718\n",
      "  0.09112176 0.1038705  0.10827595 0.09595337]\n",
      " [0.10407927 0.0909217  0.09926381 0.10152598 0.10452746 0.09233395\n",
      "  0.10610824 0.09341861 0.11267553 0.09514544]\n",
      " [0.09993791 0.09082425 0.10024345 0.100232   0.10891911 0.10039263\n",
      "  0.09576365 0.10013431 0.10940236 0.09415034]\n",
      " [0.10140203 0.09071074 0.1021142  0.09995856 0.10393928 0.09712162\n",
      "  0.09785765 0.098266   0.11073144 0.09789846]\n",
      " [0.08920852 0.09355719 0.09958879 0.10805731 0.1002538  0.09886077\n",
      "  0.10308422 0.10097962 0.11091523 0.09549455]\n",
      " [0.10372054 0.09296224 0.10073064 0.10161891 0.09716202 0.10056182\n",
      "  0.10028174 0.09496523 0.10794004 0.10005684]\n",
      " [0.10102342 0.08813482 0.0937167  0.10564534 0.1005645  0.09482563\n",
      "  0.10002442 0.10744106 0.10707358 0.10155052]\n",
      " [0.09973905 0.09241026 0.09293852 0.11030587 0.09653086 0.10002226\n",
      "  0.1009472  0.09908149 0.11195335 0.09607113]\n",
      " [0.09306992 0.09367657 0.09304508 0.10385342 0.1029242  0.10822763\n",
      "  0.09489495 0.10217277 0.11752077 0.09061469]\n",
      " [0.09670204 0.08568281 0.09935581 0.10519442 0.10825309 0.09420307\n",
      "  0.09909917 0.09937886 0.11538812 0.09674261]\n",
      " [0.10087744 0.10227204 0.09756608 0.09792155 0.0946487  0.10033119\n",
      "  0.10235169 0.10157195 0.10524053 0.09721882]\n",
      " [0.09467471 0.09257589 0.10484496 0.10827526 0.10023776 0.09797772\n",
      "  0.09680924 0.09633413 0.10986065 0.09840968]\n",
      " [0.10162626 0.09904436 0.09850459 0.10050379 0.10055054 0.09755032\n",
      "  0.09839043 0.1013341  0.1069524  0.0955432 ]\n",
      " [0.10393385 0.09668599 0.09988388 0.10255344 0.10890157 0.09441673\n",
      "  0.09368471 0.09786411 0.11042886 0.09164685]\n",
      " [0.09447608 0.09629992 0.10241832 0.11366451 0.10658841 0.09536235\n",
      "  0.09237614 0.09960319 0.10692415 0.09228693]\n",
      " [0.10165089 0.09115297 0.09583951 0.1026811  0.10610027 0.09370433\n",
      "  0.09402728 0.09933912 0.11473158 0.10077295]\n",
      " [0.10643271 0.09350849 0.10136075 0.09980093 0.09878185 0.09800227\n",
      "  0.09871592 0.10137267 0.10861355 0.09341087]\n",
      " [0.1019464  0.08693111 0.09475391 0.10036147 0.09926811 0.09687154\n",
      "  0.09810323 0.10425407 0.11713456 0.10037561]\n",
      " [0.09775856 0.09209836 0.10076274 0.10288709 0.1070168  0.09637235\n",
      "  0.10348762 0.09820463 0.10351018 0.09790166]\n",
      " [0.1016141  0.09083943 0.09975573 0.10659629 0.10607939 0.09582794\n",
      "  0.09827052 0.09765422 0.10345756 0.09990483]\n",
      " [0.09458448 0.09007587 0.09629068 0.10834656 0.10703211 0.0994261\n",
      "  0.08991003 0.1065018  0.10905334 0.09877904]\n",
      " [0.10212112 0.09169533 0.10123399 0.1043397  0.10581485 0.09723117\n",
      "  0.10053794 0.09175578 0.10970333 0.09556679]\n",
      " [0.09607127 0.09357726 0.10075389 0.10507547 0.10739929 0.09155378\n",
      "  0.09834351 0.09780114 0.11119038 0.09823401]\n",
      " [0.10132531 0.0877352  0.09928128 0.10816258 0.1106124  0.09566653\n",
      "  0.10145055 0.09811601 0.11414793 0.08350219]\n",
      " [0.09783781 0.09370263 0.09854473 0.10342383 0.10063037 0.09819123\n",
      "  0.10174885 0.09240311 0.10883784 0.1046796 ]\n",
      " [0.09770343 0.09798092 0.10231522 0.10539515 0.09688835 0.10234569\n",
      "  0.10245667 0.09519912 0.10883192 0.09088352]\n",
      " [0.09626517 0.09688302 0.09793987 0.11330591 0.10469828 0.10246686\n",
      "  0.09688198 0.09912655 0.1026185  0.08981387]\n",
      " [0.09563494 0.08778342 0.0995076  0.1075155  0.10744436 0.10049131\n",
      "  0.09530321 0.1019218  0.10570844 0.09868944]\n",
      " [0.11248534 0.0925417  0.10160959 0.0956522  0.09339707 0.09992948\n",
      "  0.1057696  0.09319845 0.11051362 0.09490295]\n",
      " [0.09272586 0.09338836 0.09339949 0.11001291 0.11637345 0.09933627\n",
      "  0.09700353 0.09000513 0.11280407 0.09495092]\n",
      " [0.09507497 0.10128615 0.10173941 0.10896216 0.10357734 0.10179542\n",
      "  0.09469488 0.09681112 0.10542965 0.09062889]\n",
      " [0.0984549  0.09729021 0.10320199 0.10357794 0.09730426 0.09677655\n",
      "  0.09702358 0.10358123 0.10842278 0.09436657]\n",
      " [0.09914398 0.0928817  0.09811042 0.09949096 0.10799214 0.10099269\n",
      "  0.09873521 0.09456564 0.10826113 0.09982613]\n",
      " [0.10027154 0.09057605 0.10684486 0.10712376 0.10073708 0.10093613\n",
      "  0.09692033 0.09963329 0.10430973 0.09264723]\n",
      " [0.09689754 0.09203638 0.09442995 0.10576499 0.10345158 0.09844914\n",
      "  0.10043451 0.10215764 0.11076377 0.0956145 ]\n",
      " [0.09738496 0.09730909 0.10129317 0.10695901 0.10349458 0.09686978\n",
      "  0.09720755 0.09728166 0.10757618 0.09462403]\n",
      " [0.09316322 0.09628126 0.09185477 0.10887421 0.11203712 0.10163773\n",
      "  0.08976862 0.09874835 0.10938047 0.09825426]\n",
      " [0.10008192 0.09401895 0.09606429 0.10840062 0.09859228 0.09797885\n",
      "  0.09645407 0.09923364 0.10986586 0.09930953]\n",
      " [0.09694428 0.09028116 0.10590723 0.10742391 0.10600982 0.09206979\n",
      "  0.10118091 0.10298753 0.10613146 0.09106391]\n",
      " [0.10345596 0.08797615 0.10196107 0.10455927 0.09807918 0.09396922\n",
      "  0.09879837 0.09926166 0.11724478 0.09469434]\n",
      " [0.10508736 0.09085774 0.0984425  0.10024398 0.10136351 0.09987001\n",
      "  0.09434477 0.09732945 0.11653029 0.09593039]\n",
      " [0.10196809 0.09030465 0.09831522 0.10468847 0.09767235 0.08708829\n",
      "  0.10067816 0.10534504 0.1131933  0.10074642]\n",
      " [0.09751366 0.08583495 0.09877563 0.10620021 0.10588404 0.10324547\n",
      "  0.10238499 0.09872344 0.1058102  0.09562741]\n",
      " [0.09014413 0.08937928 0.10213521 0.1027226  0.10359861 0.10050815\n",
      "  0.0984754  0.09960486 0.12608558 0.08734618]\n",
      " [0.0974085  0.09906453 0.09853494 0.10863382 0.09574728 0.10020237\n",
      "  0.09532088 0.1021577  0.10818925 0.09474073]\n",
      " [0.10490117 0.08810314 0.10103406 0.09909083 0.10295535 0.10011638\n",
      "  0.09601303 0.09753842 0.1121578  0.09808982]\n",
      " [0.0961171  0.08684654 0.10384646 0.10646068 0.10615901 0.10081366\n",
      "  0.09468572 0.10665999 0.10765365 0.09075721]\n",
      " [0.09875983 0.08915019 0.0961708  0.10970497 0.10253571 0.09173508\n",
      "  0.10413748 0.09567167 0.11640132 0.09573296]\n",
      " [0.09758309 0.09617128 0.09467103 0.11495353 0.10433901 0.09649609\n",
      "  0.09580326 0.10175039 0.10603858 0.09219374]\n",
      " [0.09105437 0.09285519 0.10055237 0.10114457 0.10165837 0.09748486\n",
      "  0.09923214 0.10317746 0.11533415 0.09750652]\n",
      " [0.0959525  0.0913115  0.09570964 0.10461685 0.10716517 0.09982433\n",
      "  0.09710045 0.09971557 0.11612018 0.09248382]\n",
      " [0.09355561 0.09009719 0.09993902 0.10074437 0.10115349 0.09918903\n",
      "  0.09906529 0.10247721 0.11383615 0.09994263]\n",
      " [0.1038748  0.09051906 0.09582699 0.10545592 0.10712649 0.09416709\n",
      "  0.10265929 0.1013325  0.11299243 0.08604542]\n",
      " [0.09147977 0.0948206  0.09778445 0.10396362 0.10234658 0.10025575\n",
      "  0.1026903  0.09831389 0.11421712 0.09412792]\n",
      " [0.1065731  0.09109108 0.0987592  0.10436552 0.10253152 0.10268708\n",
      "  0.09125492 0.10138995 0.10354415 0.09780348]\n",
      " [0.09851903 0.10050517 0.09559568 0.10801855 0.09591496 0.10105947\n",
      "  0.09687686 0.09966901 0.10522487 0.09861641]\n",
      " [0.10747944 0.09593938 0.10258611 0.09901055 0.10181119 0.09576239\n",
      "  0.10082888 0.0985303  0.10399546 0.09405631]\n",
      " [0.09664338 0.08857453 0.09971894 0.11177914 0.1025659  0.08854503\n",
      "  0.09469036 0.10612568 0.11623073 0.09512631]\n",
      " [0.09764049 0.09107668 0.10017857 0.10466259 0.10988114 0.09835994\n",
      "  0.10056484 0.09907125 0.10311646 0.09544803]\n",
      " [0.10472366 0.08360204 0.10592308 0.10158372 0.11226364 0.09328723\n",
      "  0.09938619 0.09130419 0.11031661 0.09760964]\n",
      " [0.10134894 0.09398617 0.09658918 0.1023131  0.10574805 0.09858595\n",
      "  0.09674556 0.10475847 0.09957614 0.10034844]\n",
      " [0.09667756 0.09494671 0.09418414 0.10267602 0.10605417 0.09791791\n",
      "  0.09831101 0.0994521  0.11027587 0.09950451]\n",
      " [0.10275413 0.08862103 0.0957052  0.10133051 0.09750423 0.09897812\n",
      "  0.09980742 0.10122372 0.11055032 0.10352533]\n",
      " [0.10044746 0.09229652 0.09553227 0.11068916 0.10597811 0.08976647\n",
      "  0.10034043 0.1008095  0.10959563 0.09454446]\n",
      " [0.10341219 0.09659259 0.09915869 0.10491221 0.10287937 0.09786854\n",
      "  0.09435278 0.09297716 0.10855436 0.09929211]\n",
      " [0.1003422  0.0846745  0.09464421 0.11058246 0.107302   0.09657607\n",
      "  0.09720133 0.09073535 0.12387481 0.09406708]\n",
      " [0.09930695 0.10159629 0.09651574 0.10540127 0.09564649 0.10215403\n",
      "  0.09665747 0.10224488 0.10364559 0.0968313 ]\n",
      " [0.08866125 0.09408933 0.10110005 0.11043522 0.09970623 0.09794826\n",
      "  0.10169029 0.1002398  0.11636553 0.08976402]\n",
      " [0.08792144 0.09798865 0.09900014 0.09823934 0.10679049 0.10025867\n",
      "  0.10205886 0.09718714 0.10923516 0.10132011]\n",
      " [0.09774906 0.09584931 0.09806772 0.10236058 0.11241342 0.0960232\n",
      "  0.0972907  0.096283   0.10749364 0.09646938]\n",
      " [0.10347818 0.09540315 0.09806205 0.096377   0.10213978 0.09814014\n",
      "  0.10273462 0.0976953  0.11139718 0.0945726 ]\n",
      " [0.09461436 0.09313204 0.09632306 0.11372334 0.10634401 0.09384447\n",
      "  0.10956779 0.09247784 0.10559757 0.09437553]\n",
      " [0.1029513  0.10030742 0.10112681 0.11025026 0.09797937 0.10208822\n",
      "  0.10003906 0.09318035 0.10189919 0.09017802]\n",
      " [0.09931984 0.0821692  0.10630673 0.0959249  0.10181008 0.09815407\n",
      "  0.09593789 0.11156132 0.11866328 0.09015268]\n",
      " [0.09412458 0.09318097 0.09877567 0.10459029 0.10041283 0.09621802\n",
      "  0.10732787 0.10092223 0.10564993 0.09879758]\n",
      " [0.09897038 0.09902452 0.09463868 0.10440863 0.10497125 0.09496804\n",
      "  0.09694242 0.0993023  0.10519322 0.10158058]\n",
      " [0.10461745 0.09557408 0.09785753 0.10319878 0.10628282 0.09306203\n",
      "  0.10774734 0.09527098 0.10607787 0.09031112]\n",
      " [0.10678405 0.0857601  0.09709932 0.10710384 0.10820614 0.09787954\n",
      "  0.09339416 0.09733913 0.10656025 0.09987348]\n",
      " [0.10252963 0.089205   0.09813451 0.10683439 0.10415122 0.09666241\n",
      "  0.09486639 0.10205904 0.11301042 0.092547  ]\n",
      " [0.09091074 0.09369572 0.09613288 0.1070057  0.11065408 0.10192236\n",
      "  0.09655394 0.09418407 0.1182619  0.09067862]\n",
      " [0.09475332 0.09076277 0.1038259  0.10373734 0.11224245 0.09470957\n",
      "  0.09956186 0.09678862 0.10892067 0.09469751]\n",
      " [0.10288671 0.09353387 0.09202763 0.10583752 0.10395334 0.10276701\n",
      "  0.09513642 0.09700697 0.11184505 0.09500546]\n",
      " [0.10204505 0.08805912 0.09208044 0.10601997 0.10153969 0.09842186\n",
      "  0.09693773 0.10860222 0.11073634 0.09555759]\n",
      " [0.09770148 0.08606762 0.10517726 0.11141449 0.10635573 0.09941999\n",
      "  0.10040137 0.09522966 0.11259232 0.08564007]\n",
      " [0.10240516 0.09045571 0.10146149 0.09583247 0.11394533 0.09072717\n",
      "  0.09852911 0.09931328 0.11410218 0.0932281 ]\n",
      " [0.09822135 0.08575885 0.09945001 0.10884646 0.10758476 0.10316245\n",
      "  0.10154229 0.09409607 0.10065278 0.10068498]\n",
      " [0.09464356 0.09473818 0.09913259 0.10589049 0.09875703 0.10351211\n",
      "  0.09928174 0.09767791 0.10855369 0.09781269]\n",
      " [0.09628434 0.09360416 0.09749321 0.10066799 0.106562   0.10237061\n",
      "  0.0952915  0.10645679 0.10773417 0.09353525]\n",
      " [0.10109325 0.09108361 0.09292486 0.10070599 0.10935369 0.09245133\n",
      "  0.09656758 0.10224861 0.12089633 0.09267475]\n",
      " [0.09719878 0.09314244 0.10279748 0.10444674 0.09676329 0.10726281\n",
      "  0.0993152  0.09874006 0.10236499 0.09796821]\n",
      " [0.09584732 0.09531779 0.10222814 0.09922486 0.10636258 0.10011797\n",
      "  0.09685822 0.10008195 0.10871208 0.09524909]\n",
      " [0.09537116 0.09009861 0.10070218 0.11034734 0.10461461 0.0968321\n",
      "  0.09755092 0.09826277 0.11057751 0.0956428 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.28574275970459, step = 11\n",
      "INFO:tensorflow:Saving checkpoints for 20 into minist_convent_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2615699768066406.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1db5bbe35f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": train_X},\n",
    "    y=train_y,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "clf.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=10,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"Cast:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-10T19:46:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from minist_convent_model\\model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-10-19:47:26\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.2706, global_step = 20, loss = 2.2507064\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20: minist_convent_model\\model.ckpt-20\n",
      "{'accuracy': 0.2706, 'loss': 2.2507064, 'global_step': 20}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": test_X},\n",
    "    y=test_y,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = clf.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
